---
title: "MUSA500 Homework 1: Using OLS Regression to Predict Median House Values in Philadelphia"
author: "Ling Chen,Hang zhao, Jiahang Li"
date: "2023-10-01"
output: html_document:
    theme: readable
    toc: true
    toc_float: true
    code_folding: "hide"
    code_download: false
    theme: united
    highlight: espresso
editor_options: 
  markdown: 
    wrap: 72
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
  message = FALSE,
	warning = FALSE)
```


```{r setup, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set()

library(tidyr)
library(dplyr)
library(DAAG)
library(car)  #to calculate VIF
library(MASS)
library(rsq)
library(kableExtra)
library(tidyverse) #for ggplot
library(sf) #for maps
library(cowplot) #for plotgrid
library(classInt)#for jenks breaks
#library(rgdal)
library(ggplot2)
library(RColorBrewer)
library(broom)
library(r2symbols)
library(lattice)

options(scipen=999)

data <- read.csv("https://raw.githubusercontent.com/Chling77/MUSA500-HW1/main/Data/RegressionData.csv")
data_geom <-st_read("D:/00Penn-学习/MUSA500/HW 1/RegressionData_geom/RegressionData.shp")

source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

palette5 <- c("#f0f9e8","#bae4bc","#7bccc4","#43a2ca","#0868ac")

```

```{r, warning = FALSE, message = FALSE}
newqBr <- function(df, variable, rnd) {
  if (missing(rnd)) {
    as.character(quantile(round(df[[variable]],4),
                          c(.01,.2,.4,.6,.8), na.rm=T))
  } else if (rnd == FALSE | rnd == F) {
    as.character(formatC(quantile(df[[variable]],
                                  c(.01,.2,.4,.6,.8), na.rm=T),
                         digits = 3))
  }
}
```

# **Introduction**

xxxxxxx

# **Methods**

## **a. Data Cleaning**

xxxxxxxxxxxxx

## **b. Exploratory Analysis**

xxxxxxxxxx

## **c. Multiple Regression Analysis**

xxxxxxxxxxxxxx

## **d. Additional Analysis**

xxxxxxxx

# **Results**

1a. using 'hist', 'mean', and 'sd' commands
```{r}
# plot all the histograms
hist(data$MEDHVAL, breaks = 50)
hist(data$NBELPOV100, breaks = 50)
hist(data$PCTBACHMOR, breaks = 50)
hist(data$PCTVACANT, breaks = 50)
hist(data$PCTSINGLES, breaks = 50)

hists <- histogram( ~ MEDHVAL +PCTBACHMOR +PCTVACANT +PCTSINGLES  +NBELPOV100, layout=c(2,3), data = data, main='Distribution of Raw Variables', sub= 'Figure 1', col="#8C96C6", breaks = 50, scales='free') 

# print out all the means
mean(data$MEDHVAL)
mean(data$NBELPOV100)
mean(data$PCTBACHMOR)
mean(data$PCTVACANT)
mean(data$PCTSINGLES)

# print out all the standard deviations
sd(data$MEDHVAL)
sd(data$NBELPOV100)
sd(data$PCTBACHMOR)
sd(data$PCTVACANT)
sd(data$PCTSINGLES)
```

1a. i. Put the result in a table

1a. ii. using 'log' command to create 5 new variables
```{r}
# create and name new log variables
data$LNMEDHVAL <- log(data$MEDHVAL + 1)
data$LNNBELPOV100 <- log(data$NBELPOV100+1)
data$LNPCTBACHMOR <- log(data$PCTBACHMOR+1)
data$LNPCTVACANT <- log(data$PCTVACANT+1)
data$LNPCTSINGLES <- log(data$PCTSINGLES+1)

```
MEDHVAL, BELPOV100: use log
other independent variables: use original variables

plot new histograms
```{r}
# plot all the histograms for new log variables
hist(LNMEDHVAL, breaks = 50)
hist(LNNBELPOV100, breaks = 50)
hist(LNPCTBACHMOR, breaks = 50)
hist(LNPCTVACANT, breaks = 50)
hist(LNPCTSINGLES, breaks = 50)

LNhists <- histogram( ~ LNMEDHVAL +LNPCTBACHMOR +LNPCTVACANT +LNPCTSINGLES  +LNNBELPOV100, layout=c(2,3), data = data, main='Distribution of Natural Log of Variables', sub= 'Figure 2', col="#B5C7F4", breaks = 50, scales='free') 
```

1b. create four scatter plots
```{r}
# create a plotting window with 2*2 array
par(mfrow=c(2,2))
plot(data$NBELPOV100, data$MEDHVAL)
plot(data$PCTBACHMOR, data$MEDHVAL)
plot(data$PCTVACANT, data$MEDHVAL)
plot(data$PCTSINGLES, data$MEDHVAL)
```

1c. Look at the Pearson Correlations using 'cor' command
```{r}
# correlation matrix
cor(data, method=c("pearson"))
```


only **LNMEDHVAL** map should be one single figure
the other four should be in one figure with four maps


```{r fig.height=6, fig.width=8}
# plot the choropleth graph for Median House Value
Plot1 <-ggplot(data_geom) +
  geom_sf(aes(fill = q5(LNMEDHVAL))) +
  scale_fill_manual(values = palette5,
                    labels= newqBr(data_geom, "LNMEDHVAL"),
                    name = "LN Median House Value\n(Quintile Breaks)")+
  labs(title = "LN Median House Value in Philadelphia",
       subtitle = "Date Source: U.S. Census",
       caption ="Figure 1")+
  mapTheme()
```

```{r fig.height=6, fig.width=8}
# plot the choropleth graph for Median House Value (another way) 感觉用连续变量可视化的图区分度不是很明显，所以后续都采用Quintile Breaks分类后的离散变量进行可视化

ggplot(data_geom) +
  geom_sf(aes(fill = LNMEDHVAL)) +
  scale_fill_distiller(palette = "YlGnBu",
                    name = "LN Median House Value") +
  labs(title = "Choropleth Map of LN Median House Value in Philadelphia",
       subtitle = "Date Source: U.S. Census",
       caption ="Figure 1")+
  mapTheme()
```


```{r fig.height=6, fig.width=8}
# plot the choropleth graph for LN number of households living in poverty
plot2 <- ggplot(data_geom) +
  geom_sf(aes(fill = q5(LNNBELPOV))) +
  scale_fill_manual(values = palette5,
                    labels= newqBr(data_geom, "LNNBELPOV"),
                    name = "LN Households in Poverty\n(Quintile Breaks)")+
  labs(title = "LN number of households living in poverty in Philadelphia",
       subtitle = "Date Source: U.S. Census",
       caption ="Figure 2")+
  mapTheme()
```

```{r fig.height=6, fig.width=8}
# plot the choropleth graph for Proportion of housing units that are vacant
plot3<- ggplot(data_geom) +
  geom_sf(aes(fill = q5(PCTVACANT))) +
  scale_fill_manual(values = palette5,
                    labels= newqBr(data_geom, "PCTVACANT"),
                    name = "Precentage of Vacant housing units(%)\n(Quintile Breaks)")+
  labs(title = "Proportion of housing units that are vacant in Philadelphia",
       subtitle = "Date Source: U.S. Census",
       caption ="Figure 3")+
  mapTheme()
```

```{r fig.height=6, fig.width=8}
# plot the choropleth graph for Percent of housing units that are detached single family houses
plot4 <- ggplot(data_geom) +
  geom_sf(aes(fill = q5(PCTSINGLES))) +
  scale_fill_manual(values = palette5,
                    labels= newqBr(data_geom, "PCTSINGLES"),
                    name = "Precentage of housing units:detached single family houses(%)\n(Quintile Breaks)")+
  labs(title = "Percent of housing units that are detached single family houses in Philadelphia",
       subtitle = "Date Source: U.S. Census",
       caption ="Figure 4")+
  mapTheme()
```

```{r fig.height=6, fig.width=8}
# plot the choropleth graph for Proportion of residents in Block Group with at least a bachelor’s degree
plot5 <- ggplot(data_geom) +
  geom_sf(aes(fill = q5(PCTBACHMOR))) +
  scale_fill_manual(values = palette5,
                    labels= newqBr(data_geom, "PCTBACHMOR"),
                    name = "Precentage of residents with at least a bachelor's degree(%)\n(Quintile Breaks)")+
  labs(title = "Proportion of residents in Block Group with at least a bachelor’s degree in Philadelphia",
       subtitle = "Date Source: U.S. Census",
       caption ="Figure 5")+
  mapTheme()
```

```{r}
mapgrid <- plot_grid( plot2, 
                      plot3, 
                      plot4, 
                      plot5,
                      align = c("hv","hv","hv","hv"),
                          ncol = 2, nrow = 2)
```


2. exploratory analysis of the data
```{r}
# first clean the data
any(is.infinite(LNNBELPOV100))
# replace inf value to NA
LNNBELPOV100[is.infinite(LNNBELPOV100)] <- NA
# then replace na value to 0
LNNBELPOV100[is.na(LNNBELPOV100)] <- 0
```

2a. using 'lm' command to run regression
```{r}
# run the 'lm' function
lm1 <- lm(LNMEDHVAL ~ PCTVACANT + PCTSINGLES + PCTBACHMOR + LNNBELPOV100, 
          data=data)
```

2b. present the summary of the fit
```{r}
# print out the statistical summary table
summary(lm1)
```
```{r}
# check the anova result
anova(lm1)
```


$$
Y \sim X\beta_0 + X\beta_1 + \epsilon
$$

$$
\epsilon \sim N(0,\sigma^2)
$$
2c. using 'fitted', 'residuals', and 'rstandard' commands
```{r}
# run 'fitted', 'residuals', and 'standardized' functions
fit <- fitted(lm1)
SSE <- residuals(lm1)
standardized <- rstandard(lm1)
```

2d. create the scatter plot, standardized versus fit
```{r}
# plot the standardized residuals versus predicted values scatter graph
plot(fit, standardized)
```

3. using stepwise regression and determine best model
```{r}
best_model <- lm(LNMEDHVAL ~ PCTVACANT + PCTSINGLES + PCTBACHMOR + LNNBELPOV100, data=data)
step <- stepAIC(best_model, direction="both")
# stepwise regression - Analysis of Variance (ANOVA)
step$anova
```
#kfold
fit <- lm(MEDHVAL~ PCTBACHMOR + PCTVACANT + MEDHHINC + PCTSINGLES, data=assignmentdata)
summary(fit)
cv <- CVlm(data=assignmentdata, fit, m=5)
mse <- attr(cv, "ms")
rmse <- sqrt(mse)						#Obtaining RMSE for model 1
rmse

#model2
fit <- lm(MEDHVAL~ PCTVACANT + MEDHHINC, data=assignmentdata)
summary(fit)
cv <- CVlm(data=assignmentdata, fit, m=5)
mse <- attr(cv, "ms")
rmse <- sqrt(mse)						#Obtaining RMSE for model 1
rmse
